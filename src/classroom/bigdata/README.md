<div align="center">
    <h1>‚öôÔ∏è DataGraphX ‚Äî Big Data + IA/ML + Grafos + Blockchain + Algoritmos Evolutivos</h1>
  <p>Plataforma integral para dise√±ar, ejecutar y gobernar <b>pipelines de datos a escala</b>, entrenar y desplegar <b>modelos de IA/ML</b>, realizar <b>anal√≠tica en grafos</b>, asegurar <b>trazabilidad y pruebas de integridad en blockchain</b> y optimizar con <b>algoritmos evolutivos</b>.</p>

  <!-- Badges -->
  <p>
    <a href="https://www.python.org/"><img alt="Python" src="https://img.shields.io/badge/Python-3.10 | 3.11-3776AB?logo=python"></a>
    <a href="https://spark.apache.org/"><img alt="Apache Spark" src="https://img.shields.io/badge/Spark-3.x-E25A1C?logo=apachespark&logoColor=white"></a>
    <a href="https://pytorch.org/"><img alt="PyTorch" src="https://img.shields.io/badge/PyTorch-ready-EE4C2C?logo=pytorch&logoColor=white"></a>
    <a href="../LICENSE"><img alt="License: MIT" src="https://img.shields.io/badge/License-MIT-blue.svg"></a>
    <a href="https://colab.research.google.com/"><img alt="Colab" src="https://img.shields.io/badge/Colab-ready-F9AB00?logo=googlecolab"></a>
    <a href="#"><img alt="Code Style: Black" src="https://img.shields.io/badge/code%20style-black-000000.svg?logo=python"></a>
    <a href="#"><img alt="CI" src="https://img.shields.io/badge/CI-GitHub%20Actions-success?logo=github"></a>
    <a href="#"><img alt="Containers" src="https://img.shields.io/badge/Docker-compose-2496ED?logo=docker&logoColor=white"></a>
  </p>

  <!-- Navigation -->
  <p>
    <a href="./notebooks/"><img alt="Notebooks" src="https://img.shields.io/badge/üìì%20Notebooks-IA/BigData-orange"></a>
    <a href="./src/"><img alt="Source Code" src="https://img.shields.io/badge/üì¶%20Source-Core-purple"></a>
    <a href="./dags/"><img alt="DAGs" src="https://img.shields.io/badge/üõ∞Ô∏è%20Orchestration-Airflow/Ray-lightgrey"></a>
    <a href="./references/"><img alt="References" src="https://img.shields.io/badge/üìö%20References-Docs-lightgrey"></a>
  </p>
</div>

---

## üéØ Visi√≥n General

**DataGraphX** unifica pilares modernos de ingenier√≠a y ciencia de datos:

* **Big Data / Lakehouse**: ingesta batch + streaming (Kafka), capa **Bronze/Silver/Gold** en **Parquet/Delta/Iceberg**, calidad y contratos de datos.
* **IA/ML & MLOps**: *feature store*, *training pipelines*, seguimiento de experimentos, *model registry* y despliegue (batch/serving/streaming).
* **Grafos**: algoritmos distribuidos (PageRank, Louvain, Shortest Paths, Node2Vec) en Spark/GraphFrames/GraphX y bases de grafos (Neo4j/PG).
* **Blockchain**: anclaje de *hashes* y metadatos (Merkle) para **inmutabilidad**, no repudio y verificaci√≥n de artefactos (datasets, modelos).
* **Algoritmos Evolutivos**: optimizaci√≥n de hiperpar√°metros, selecci√≥n de rasgos, *neural architecture search*, calendarizaci√≥n y *query planning*.

Incluye APIs limpias en Python, DAGs de orquestaci√≥n, notebooks demostrativos y utilidades para benchmarking/observabilidad.

---

## üìÇ Estructura del Repositorio

```
DataGraphX/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ notebooks/                   # Tutoriales y experimentos (Colab-ready)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ datalake/                # IO, particionado, Delta/Iceberg/Hudi
‚îÇ   ‚îú‚îÄ‚îÄ ingest/                  # Conectores (batch/streaming), esquemas
‚îÇ   ‚îú‚îÄ‚îÄ quality/                 # Great Expectations, data contracts
‚îÇ   ‚îú‚îÄ‚îÄ pipelines/               # ETL/ELT, medallion (Bronze/Silver/Gold)
‚îÇ   ‚îú‚îÄ‚îÄ ml/                      # features, training, evaluation, registry
‚îÇ   ‚îú‚îÄ‚îÄ graph/                   # GraphFrames/NetworkX/Neo4j utils
‚îÇ   ‚îú‚îÄ‚îÄ evo/                     # Algoritmos evolutivos (CMA-ES, NSGA-II)
‚îÇ   ‚îú‚îÄ‚îÄ chain/                   # Anclaje blockchain (Merkle, firmas)
‚îÇ   ‚îú‚îÄ‚îÄ serving/                 # REST/gRPC, batch scoring, streaming
‚îÇ   ‚îî‚îÄ‚îÄ viz/                     # Dashboards y gr√°ficos
‚îú‚îÄ‚îÄ dags/                        # Airflow/Ray/Dagster
‚îú‚îÄ‚îÄ infra/                       # Docker/K8s/Terraform (opcional)
‚îú‚îÄ‚îÄ config/                      # YAMLs centralizados
‚îú‚îÄ‚îÄ tests/                       # Unit/property/integration tests
‚îú‚îÄ‚îÄ data/                        # /raw (Bronze), /curated (Silver), /marts (Gold)
‚îú‚îÄ‚îÄ references/                  # Papers, enlaces y notas
‚îî‚îÄ‚îÄ pyproject.toml               # Dependencias/estilo/packaging
```

---

## üéì Objetivos de Aprendizaje

1. **Dise√±ar** arquitectura **lakehouse** y pipelines h√≠bridos *batch/streaming* con calidad/lineage.
2. **Entrenar/servir** modelos de ML/Deep Learning con MLOps (versionado, monitoreo, *drift*).
3. **Aplicar** anal√≠tica de **grafos** a problemas de fraude, recomendaci√≥n, log√≠stica y KGs.
4. **Garantizar** trazabilidad e integridad con **blockchain** (anclaje de artefactos).
5. **Optimizar** tareas complejas con **algoritmos evolutivos** (HPO, selecci√≥n de rasgos, NAS).
6. **Escalar** con Spark/Ray/Dask, *vectorization*, GPU (RAPIDS/cuDF/cuGraph) cuando corresponda.

> **Nota**: este repositorio tiene fines educativos/t√©cnicos. No sustituye asesoramiento **financiero/m√©dico/legal**. Para decisiones cr√≠ticas, consulta con profesionales.

---

## üìú Instalaci√≥n R√°pida

**Requisitos**: Python ‚â• 3.10, Java 8+ (para Spark), opcional Docker.

```bash
git clone <URL_DEL_REPOSITORIO>
cd DataGraphX
python -m venv .venv
source .venv/bin/activate          # en Windows: .venv\Scripts\activate
pip install -U pip
pip install -e ".[all]"            # spark, pyspark, ray, dask, mlflow, graphframes, neo4j, deap, optuna
pre-commit install
```

Opcional (contenedores):

```bash
docker compose up -d               # kafka, spark-thrift, mlflow, neo4j, minio
```

---

## üß™ Quickstart

### CLI ‚Äî Pipeline de ejemplo (Bronze‚ÜíGold + Modelo + Anclaje)

```bash
# 1) Ingesta streaming desde Kafka a Bronze (Delta)
python -m src.ingest.kafka_to_delta --topic transacciones --out data/raw/tx

# 2) Curaci√≥n a Silver y features a Gold
python -m src.pipelines.curate --in data/raw/tx --out data/curated/tx_silver
python -m src.pipelines.features --in data/curated/tx_silver --out data/marts/tx_gold

# 3) Entrenamiento con HPO evolutivo y registro de experimento
python -m src.ml.train --data data/marts/tx_gold --algo xgboost \
  --hpo evo --max-gen 20 --pop-size 40 --mlflow-uri http://localhost:5000

# 4) Anclaje en blockchain (hash de dataset + modelo + m√©tricas)
python -m src.chain.anchor --artifacts runs/last --network sepolia
```

### Python API ‚Äî ETL + Grafos + Scoring

```python
import pyspark.sql.functions as F
from pyspark.sql import SparkSession
from src.graph.api import pagerank_graphframe
from src.ml.serving import load_model, batch_score

spark = SparkSession.builder.getOrCreate()

# 1) Cargar Silver y construir un grafo de relaciones
edges = spark.read.parquet("data/curated/tx_edges_silver")
vertices = spark.read.parquet("data/curated/parties_silver")
pr = pagerank_graphframe(vertices, edges, max_iter=20, reset_prob=0.15)

# 2) Enriquecer Gold con centralidad PageRank
gold = spark.read.parquet("data/marts/tx_gold").join(pr, on="party_id", how="left")

# 3) Scoring batch con el √∫ltimo modelo registrado
model = load_model("fraud_xgb@Production")
pred = batch_score(model, gold)
pred.write.mode("overwrite").parquet("data/marts/tx_scores")
```

---

## üìú Tabla de Contenidos

* [1. Arquitectura de Datos (Lakehouse)](#1-arquitectura-de-datos-lakehouse)
* [2. Ingesta & Calidad](#2-ingesta--calidad)
* [3. Procesamiento & Rendimiento](#3-procesamiento--rendimiento)
* [4. IA/ML & MLOps](#4-iaml--mlops)
* [5. Anal√≠tica de Grafos](#5-anal√≠tica-de-grafos)
* [6. Blockchain: Trazabilidad & Integridad](#6-blockchain-trazabilidad--integridad)
* [7. Algoritmos Evolutivos](#7-algoritmos-evolutivos)
* [8. Observabilidad & Gobierno](#8-observabilidad--gobierno)
* [9. Roadmap de Notebooks](#9-roadmap-de-notebooks)
* [10. Ejercicios Propuestos](#10-ejercicios-propuestos)
* [11. Errores Comunes](#11-errores-comunes)
* [12. API Breve](#12-api-breve)
* [13. C√≥mo Contribuir](#13-c√≥mo-contribuir)
* [14. Licencia](#14-licencia)
* [Ap√©ndice A: Diagramas Mermaid](#ap√©ndice-a-diagramas-mermaid)
* [Ap√©ndice B: Pseudoc√≥digo Clave](#ap√©ndice-b-pseudoc√≥digo-clave)
* [Ap√©ndice C: Plantilla de Experimento](#ap√©ndice-c-plantilla-de-experimento)

---

## 1. Arquitectura de Datos (Lakehouse)

**Patr√≥n Medallion**:

* **Bronze** (*raw*): ingesti√≥n cruda, particionada por `event_date` y `source`.
* **Silver** (*curated*): limpieza, tipado, deduplicaci√≥n, *slowly changing dimensions*.
* **Gold** (*marts/features*): tablas anal√≠ticas y *feature views* para ML/BI.

**Lambda/Kappa**: lotes (batch) + *streams* con ventanas (tumbling, hopping), *watermarks* y *exactly-once* mediante transacciones (Delta/Iceberg/Hudi).

**L√≠nea de datos**: *OpenLineage* y *data catalog* (column-level lineage), contratos de datos (esquemas + reglas) y *change data capture* (CDC).

---

## 2. Ingesta & Calidad

* Conectores **batch** (S3/GCS/Azure, JDBC, APIs) y **streaming** (Kafka, Pulsar).
* **Schema Registry** (Avro/Protobuf/JSON) + evoluci√≥n de esquemas.
* **Calidad**: *Great Expectations*, *assertions* de dominio y controles de **idempotencia**.
* **PII**: detecci√≥n y *tokenization*; cumplimiento de retenci√≥n.

Ejemplo de contrato (YAML):

```yaml
dataset: tx_silver
schema:
  - name: tx_id       ; type: string ; unique: true
  - name: amount      ; type: decimal(18,2) ; nullable: false ; min: 0.0
  - name: event_time  ; type: timestamp ; nullable: false
rules:
  - name: positive_amount ; expr: amount >= 0
  - name: valid_time      ; expr: event_time >= '2020-01-01'
```

---

## 3. Procesamiento & Rendimiento

* **Spark** para *joins* grandes, *windowing*, UDF/SQL; **Ray/Dask** para cargas Python-first.
* **Formatos** columnares (Parquet), **particionado** y **Z-Ordering**; *broadcast* y *bucketing* donde aplique.
* **Algoritmos aproximados**: *HyperLogLog*, *Count-Min Sketch*, *Bloom Filters*; *reservoir sampling*.
* **GPU**: RAPIDS (**cuDF/cuML/cuGraph**) cuando la relaci√≥n *I/O ‚Üî compute* lo justifique.
* **Caching** y *checkpointing* en *streams* para resiliencia.

---

## 4. IA/ML & MLOps

* **Feature Store**: definiciones declarativas, *point-in-time correctness*, materializaciones Gold.
* **HPO**: *grid/random*, **bayesiano**, **evolutivo** (CMA-ES, NSGA-II, algoritmos gen√©ticos).
* **Tracking**: artefactos, m√©tricas y par√°metros (MLflow); **Model Registry** con *staging/production*.
* **Despliegue**: *batch scoring*, *stream scoring* (mapGroupsWithState), REST/gRPC con validaci√≥n.
* **Monitoreo**: *data drift*, *performance decay*, *concept drift* y alertas.

Ejemplo: entrenamiento XGBoost con b√∫squeda evolutiva (pseudo-CLI disponible arriba).

---

## 5. Anal√≠tica de Grafos

* **Modelado**: `V(vertices)`, `E(edges)` con atributos (peso, tipo, timestamps).
* **Algoritmos** (distribuidos/monom√°quina):

  * Centralidad: PageRank, Betweenness (aprox.), Degree.
  * Comunidades: Louvain/Leiden.
  * Caminos: SSSP/Dijkstra, BFS, *Reachability*.
  * **Embeddings**: Node2Vec/DeepWalk para downstream ML.
* **Bases de grafos**: conectores a **Neo4j** / **PG con extensiones de grafos**.
* **Casos**: fraude (ciclos/rings), supply chain, recomendaciones, KGs para RAG.

---

## 6. Blockchain: Trazabilidad & Integridad

* **¬øQu√© anclamos?** Manifiestos de datasets (paths, *schema hash*, recuentos), modelos (pesos, firmas), m√©tricas y DAGs.
* **C√≥mo**: √°rbol de **Merkle** ‚Üí *root hash* firmado y publicado en red (p.ej., EVM/Hyperledger). Conserva privacidad (no subes datos), garantiza **no repudio**.
* **Smart contracts**: registro m√≠nimo (*event logs* + mapping de `artifact_id ‚Üí merkle_root`), *role-based access* para admisi√≥n.

> **Recomendaci√≥n**: usar anclaje peri√≥dico (*checkpoints*) y vincularlo al lineage para auditor√≠as reproducibles.

---

## 7. Algoritmos Evolutivos

**Aplicaciones**:

* **HPO** (hiperpar√°metros), **selecci√≥n de rasgos**, **NAS** (arquitecturas), **schedule de jobs**, **optimizaci√≥n multiobjetivo** (AUC ‚Üî latencia ‚Üî costo).

**Modelo gen√©rico (GA/ES)**:

* **Genoma**: codifica hiperpar√°metros/rasgos/arquitecturas.
* **Poblaci√≥n** inicial (muestreo estratificado / *warm start*).
* **Fitness**: m√©trica(s) objetivo + penalizaciones (SLA, tama√±o modelo).
* **Operadores**: *crossover*, *mutaci√≥n*, *elitismo*; *constraints* con reparaci√≥n/penalizaci√≥n.
* **Paralelismo**: evaluaci√≥n distribuida (Spark/Ray), *early stopping* y poda.

---

## 8. Observabilidad & Gobierno

* **Logging/tracing** por job, *data lineage* y *run metadata*.
* **KPIs**: *throughput*, *latencia P95*, costo, % fallos, *freshness*, *feature coverage*.
* **Seguridad/privacidad**: RBAC/ABAC, enmascaramiento, *differential privacy* (cuando aplique).
* **SLOs**: definiciones declarativas y alertas.

---

## 9. Roadmap de Notebooks

| Notebook                     | Tema                                             |                                         Colab                                         |
| :--------------------------- | :----------------------------------------------- | :-----------------------------------------------------------------------------------: |
| `01_lakehouse.ipynb`         | Medallion, Delta/Iceberg, partici√≥n y Z-Ordering | <a href="#"><img src="https://colab.research.google.com/assets/colab-badge.svg"/></a> |
| `02_streaming_kafka.ipynb`   | Ventanas, watermarks, exactly-once               | <a href="#"><img src="https://colab.research.google.com/assets/colab-badge.svg"/></a> |
| `03_ml_hpo_evo.ipynb`        | HPO evolutivo (CMA-ES/NSGA-II) en Ray            | <a href="#"><img src="https://colab.research.google.com/assets/colab-badge.svg"/></a> |
| `04_graph_analytics.ipynb`   | PageRank/Louvain/Node2Vec con GraphFrames/Neo4j  | <a href="#"><img src="https://colab.research.google.com/assets/colab-badge.svg"/></a> |
| `05_blockchain_anchor.ipynb` | Merkle roots, firmas y publicaci√≥n de anclajes   | <a href="#"><img src="https://colab.research.google.com/assets/colab-badge.svg"/></a> |
| `06_monitoring_mlop.ipynb`   | Drift, monitoreo y retraining                    | <a href="#"><img src="https://colab.research.google.com/assets/colab-badge.svg"/></a> |

---

## 10. Ejercicios Propuestos

**Arquitectura**

1. Dise√±a un esquema de **particionado** y **ordenamiento** para `tx_gold` considerando consultas top-N por usuario y rango temporal.
2. Implementa **CDC** con *merge into* (upserts) y eval√∫a *write amplification*.

**ML/Grafos**

1. Entrena un modelo de fraude que incorpore **PageRank** y **Node2Vec** como *features*. Compara vs. baseline tabular.
2. Ejecuta **NSGA-II** para maximizar AUC y minimizar latencia de inferencia.

**Blockchain**

1. Implementa un *Merkleizer* que produzca `root` para un manifiesto y verif√≠calo contra un contrato de prueba.

---

## 11. Errores Comunes

* ‚ùå Ignorar **time travel** y mezclar *train/test* temporal ‚Üí *leakage*.
* ‚ùå No definir **SLA/SLO** y sobreoptimizar m√©trica offline sin constraints operativos.
* ‚ùå Feature store sin **point-in-time correctness**.
* ‚ùå **Skew** en joins sin *salting/bucketing* ‚Üí *tasks* colgadas.
* ‚ùå HPO sin **presupuesto** ni **poda** ‚Üí costos descontrolados.

---

## 12. API Breve

```python
# src/ingest/kafka_to_delta.py
ingest(topic: str, out_path: str, checkpoint: str, schema: dict) -> None

# src/pipelines/curate.py
curate(in_path: str, out_path: str, rules: dict) -> None

# src/ml/train.py
train(data_path: str, algo: str, hpo: str="evo", **kwargs) -> RunInfo

# src/graph/api.py
pagerank_graphframe(V, E, max_iter=20, reset_prob=0.15) -> DataFrame
louvain_graphframe(V, E) -> (communities_df, modularity)

# src/evo/search.py
nsga2(objectives: list, search_space: dict, budget: int) -> list

# src/chain/anchor.py
anchor(artifacts_dir: str, network: str="testnet") -> TxReceipt
verify(artifact_id: str, network: str="testnet") -> bool
```

---

## 13. C√≥mo Contribuir

1. **Fork** y rama (`feature/<mi-aporte>`).
2. Cumple estilo (Black/ruff) y agrega **tests**.
3. Ejecuta `pre-commit run -a` y `pytest -q`.
4. PR con **descripci√≥n clara**, *benchmarks* y diagramas si aplica.

---

## 14. Licencia

C√≥digo bajo **MIT**. Contenidos (texto/notebooks/figuras) bajo **CC BY 4.0**. Ver `LICENSE`.

---

## Ap√©ndice A: Diagramas Mermaid

### A.1 Arquitectura Lakehouse + MLOps + Grafos + Blockchain

```mermaid
flowchart LR
  subgraph Ingesta
    K["Kafka"] --> B["Bronze (Delta)"]
    JB["JDBC/API"] --> B
  end
  subgraph "Curaci√≥n"
    B --> S["Silver"]
    QC["Quality/Contracts"] --> S
  end
  subgraph "Features/Gold"
    S --> G["Gold (Marts/Features)"]
    G --> FS["Feature Store"]
  end
  subgraph "ML/MLOps"
    FS --> TR["Training"]
    TR --> MR["Model Registry"]
    MR --> SV["Serving"]
    MON["Monitoring/Drift"] --> TR
  end
  subgraph Grafos
    S --> V["Vertices"]
    S --> E["Edges"]
    V & E --> GA["Graph Analytics"]
    GA --> G
  end
  subgraph Blockchain
    MAN["Manifest/Hashes"] --> MRK["Merkle Root"]
    MRK --> SC["Smart Contract"]
  end
  SV --> MAN
  G --> MAN
```

### A.2 HPO Evolutivo (NSGA-II)

```mermaid
flowchart TD
  A["Init Poblaci√≥n"] --> B["Evaluar Fitness (AUC, Latencia)"]
  B --> C["Seleccionar Padres"]
  C --> D["Crossover/Mutaci√≥n"]
  D --> E["Evaluar Offspring"]
  E --> F["Unir & No Dominated Sorting"]
  F --> G{"¬øPresupuesto?"}
  G -- No --> C
  G -- S√≠ --> H["Frente de Pareto"]
```

---

## Ap√©ndice B: Pseudoc√≥digo Clave

**B.1 PageRank distribuido (esqueleto)**

```
repeat until convergencia or max_iter:
  rank = contribs.outDegreeJoin().mapValues(sum) * alpha + (1 - alpha) / N
```

**B.2 Merkle Root de artefactos**

```
files = sort(list_artifacts(dir))
leafs = [hash(file_bytes(f)) for f in files]
while len(leafs) > 1:
    leafs = [ hash(leafs[i] + leafs[i+1]) for i in range(0, len(leafs), 2) ]
root = leafs
```

**B.3 Esqueleto de fitness para HPO evolutivo**

```python
def fitness(cfg):
    model = build_model(cfg)
    metrics = cross_val_score(model, train_data)
    latency = measure_latency(model, sample_batch)
    return {"auc": metrics["auc"], "lat": latency}
```

---

## Ap√©ndice C: Plantilla de Experimento

```markdown
# <T√≠tulo: p.ej., HPO evolutivo para XGBoost con restricciones de latencia>

## 1. Objetivos
- M√©tricas objetivo, restricciones operativas y presupuesto de evaluaci√≥n.

## 2. Datos
- Fuentes, *time split*, *point-in-time*, *leakage* evitado.

## 3. Metodolog√≠a
- Espacio de b√∫squeda, operadores, criterios de parada y *early pruning*.

## 4. Resultados
- Frentes de Pareto, importancia de rasgos, sensibilidad.

## 5. Costos y Riesgos
- Uso de recursos, fallas y mitigaciones.

## 6. Conclusiones
- Recomendaciones y trabajo futuro.
```

---

## üìö Referencias y Recursos

* Lakehouse/Medallion, *stream processing*, *approximate algorithms*, MLOps, grafos y blockchain ‚Äî ver `references/`.
* Buenas pr√°cticas: *time-travel*, *point-in-time correctness*, *data contracts*, *lineage*, *drift monitoring*, *Pareto optimization*.
```
