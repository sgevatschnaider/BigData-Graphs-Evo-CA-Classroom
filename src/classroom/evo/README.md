<div align="center">
  <h1>üß¨ EvoAlgo ‚Äî README</h1>
  <p>Teor√≠a y pr√°ctica aplicada de <b>Algoritmos Evolutivos (EA)</b> para docencia y desarrollo.</p>

## Recurso visual ‚Äî Frente de Pareto (MOEA)

Animaci√≥n del **frente de Pareto** (2 objetivos) y el avance de una poblaci√≥n **NSGA-II**: √∫til para introducir **dominancia**, **diversidad** (crowding) y **elitismo** en multiobjetivo. &#x20;

![Animaci√≥n de Frente de Pareto](images/pareto.gif)

  <p>
    <a href="https://www.python.org/"><img alt="Python" src="https://img.shields.io/badge/Python-3.10%20|%203.11-blue"></a>
    <a href="../LICENSE"><img alt="License: MIT" src="https://img.shields.io/badge/License-MIT-blue.svg"></a>
    <a href="https://pre-commit.com/"><img alt="pre-commit" src="https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white"></a>
  </p>

  <p>
    <a href="./notebooks/"><img alt="Notebooks" src="https://img.shields.io/badge/üìì%20Notebooks-EA-orange"></a>
    <a href="./data/"><img alt="Data" src="https://img.shields.io/badge/üóÇÔ∏è%20Data-benchmarks|config-lightgrey"></a>
    <a href="./images/"><img alt="Images" src="https://img.shields.io/badge/üñºÔ∏è%20Images-diagrams|figures-lightgrey"></a>
    <a href="./references/"><img alt="References" src="https://img.shields.io/badge/üìö%20References-papers|books-lightgrey"></a>
  </p>
</div>

---

## Estructura local

```
EvoAlgo/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ notebooks/
‚îú‚îÄ‚îÄ src/               # operadores, estrategias y utilidades
‚îú‚îÄ‚îÄ data/              # instancias (TSP, knapsack, etc.)
‚îú‚îÄ‚îÄ images/            # figuras y gifs docentes
‚îî‚îÄ‚îÄ references/        # bibliograf√≠a, slides, bibtex
```

---

## Objetivos de aprendizaje

Al completar esta secci√≥n podr√°s:

* Entender el **ciclo general** de un EA: inicializaci√≥n ‚Üí **selecci√≥n parental** ‚Üí **recombinaci√≥n** ‚Üí **mutaci√≥n** ‚Üí **selecci√≥n ambiental** ‚Üí parada.&#x20;
* Conocer familias principales: **GA/SGA**, **ES**, **EP**, **GP** (historia, representaci√≥n y operadores).&#x20;
* Implementar **DE** (Differential Evolution) y **PSO** (Swarm) y compararlos con GA/ES. &#x20;
* Aplicar **MOEA**: Pareto, **NSGA-II/III**, descomposici√≥n (MOEA/D) e hipervolumen. &#x20;
* Relacionar principios (variaci√≥n + selecci√≥n) con el **Teorema No Free Lunch** para dise√±o de variantes espec√≠ficas al dominio.&#x20;

---

## Instalaci√≥n r√°pida

Requisitos sugeridos:

* Python ‚â• 3.10
* Paquetes: `numpy`, `pandas`, `matplotlib`, `scipy`, `jupyter`, `deap`, `pymoo`, `cmaes`, `nevergrad`
* *(opcionales)*: `networkx` (TSP/graph utils), `plotly` (figuras interactivas)

```bash
# Desde EvoAlgo/
python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -U pip
pip install numpy pandas matplotlib scipy jupyter deap pymoo cmaes nevergrad
jupyter lab  # o jupyter notebook
```

Abre los cuadernos en `notebooks/` para la ruta guiada.

---

## Tabla de contenidos

* [1) Fundamentos te√≥ricos](#1-fundamentos-te√≥ricos)
* [2) Componentes de un EA](#2-componentes-de-un-ea)
* [3) Algoritmos esenciales (y complejidad pr√°ctica)](#3-algoritmos-esenciales-y-complejidad-pr√°ctica)
* [4) Optimizaci√≥n multiobjetivo (MOEA)](#4-optimizaci√≥n-multiobjetivo-moea)
* [5) Pr√°ctica con datos](#5-pr√°ctica-con-datos)
* [6) Buenas pr√°cticas (ingenier√≠a + docencia)](#6-buenas-pr√°cticas-ingenier√≠a--docencia)
* [7) Aplicaciones t√≠picas](#7-aplicaciones-t√≠picas)
* [8) Roadmap sugerido de notebooks](#8-roadmap-sugerido-de-notebooks)
* [9) Ejercicios propuestos](#9-ejercicios-propuestos)
* [10) Errores comunes](#10-errores-comunes)
* [11) Enlaces internos y bibliograf√≠a](#11-enlaces-internos-y-bibliograf√≠a)
* [12) Contribuci√≥n](#12-contribuci√≥n)
* [13) Licencia](#13-licencia)
* [Ap√©ndice A ‚Äî Pseudoc√≥digo docente](#ap√©ndice-a--pseudoc√≥digo-docente)
* [Ap√©ndice B ‚Äî Plantilla m√≠nima de notebook](#ap√©ndice-b--plantilla-m√≠nima-de-notebook)

---

## 1) Fundamentos te√≥ricos

**Resumen EA.** Los EA son **meta-algoritmos robustos** de b√∫squeda estoc√°stica basados en poblaci√≥n; recombinaci√≥n y mutaci√≥n crean variaci√≥n, y la selecci√≥n dirige la b√∫squeda.&#x20;
**NFL.** No existe ‚Äúel mejor algoritmo‚Äù universal; conviene crear variantes espec√≠ficas de dominio (representaci√≥n + operadores).&#x20;

---

## 2) Componentes de un EA

* **Representaci√≥n**: binaria, enteros, reales, permutaciones, √°rboles/programas, grafos, etc.&#x20;
* **Selecci√≥n parental**: ruleta, **SUS**, **torneo** (k peque√±o).&#x20;
* **Recombinaci√≥n**: 1-punto / uniforme / aritm√©tica (para reales). &#x20;
* **Mutaci√≥n**: bit-flip (SGA), normales sesgadas/no sesgadas (reales). &#x20;
* **Selecci√≥n ambiental (ES)**: esquemas (Œº,Œª) y (Œº+Œª).&#x20;

---

## 3) Algoritmos esenciales (y complejidad pr√°ctica)

| Familia    | Idea (muy breve)                                                           | Notas clave                                          |
| ---------- | -------------------------------------------------------------------------- | ---------------------------------------------------- |
| **SGA/GA** | Poblaci√≥n binaria, **ruleta**, **1-punto**, **bit-flip**                   | Esqueleto can√≥nico de Holland/DeJong/Goldberg.       |
| **ES**     | Reales + *self-adaptation* de pasos; selecci√≥n (Œº,Œª)/(Œº+Œª)                 | Ciclo ES y 1/5-rule (hist√≥rico).                     |
| **DE**     | Mutaci√≥n por **diferencias**: $v = x_a + F(x_b-x_c)$; *rand/1*, *best/1*   | Cruce uniforme con resguardo; reemplazo por mejor.   |
| **PSO**    | Part√≠culas con memoria: $v \leftarrow v + c_1 r (pBest-x)+c_2 r (gBest-x)$ | Sin operadores gen√©ticos; cooperaci√≥n v√≠a gBest.     |

> **Nota docente**: el **ciclo general EA** unifica estas variantes (difiere en representaci√≥n/operadores/selecci√≥n).&#x20;

---

## 4) Optimizaci√≥n multiobjetivo (MOEA)

**Dominancia y Pareto.** Definiciones formales y frente de Pareto para $f_1,\dots,f_n$. &#x20;

**NSGA-II.** Corrige NSGA: reemplaza *niching dshare* por **crowding distance**; introduce **elitismo** (uni√≥n P‚à™Q y truncamiento por frentes + crowding). &#x20;

**NSGA-III.** Para muchos objetivos: **puntos de referencia** y selecci√≥n por direcciones subrepresentadas. &#x20;

**Otros MOEA.** VEGA, descomposici√≥n (MOEA/D), hipervolumen.&#x20;

**Mermaid ‚Äî esquema NSGA-II (alto nivel):**

```mermaid
flowchart LR
  P0[Padres P_t] --> Q0[Variaci√≥n: crossover+mutaci√≥n]
  Q0 --> M0[P' (offspring)]
  M0 --> U0[Uni√≥n U = P_t ‚à™ P']
  U0 --> S0[Ordenar por frentes no dominados]
  S0 --> T0[Truncar por crowding distance]
  T0 --> P1[Nueva poblaci√≥n P_{t+1}]
```

---

## 5) Pr√°ctica con datos

### 5.1 Formatos en `data/`

* `*.tsp` / `*.csv` (coordenadas, matrices de distancias), `knapsack/*.csv` (√≠tems, pesos, valores), JSON/YAML para **configs de experimento**.

### 5.2 Quick-start (SGA m√≠nimo con DEAP)

```python
import random, numpy as np
from deap import base, creator, tools

# Maximize f(x) = sum(bits)
N = 50
creator.create("FitnessMax", base.Fitness, weights=(1.0,))
creator.create("Individual", list, fitness=creator.FitnessMax)

toolbox = base.Toolbox()
toolbox.register("attr_bool", random.randint, 0, 1)
toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_bool, N)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)
toolbox.register("evaluate", lambda ind: (sum(ind),))
toolbox.register("mate", tools.cxOnePoint)
toolbox.register("mutate", tools.mutFlipBit, indpb=1.0/N)
toolbox.register("select", tools.selTournament, tournsize=3)

pop = toolbox.population(n=100)
for _ in range(100):
    off = tools.selTournament(pop, len(pop), 3)
    off = list(map(toolbox.clone, off))
    for c1, c2 in zip(off[::2], off[1::2]): tools.cxOnePoint(c1, c2)
    for ind in off: toolbox.mutate(ind); del ind.fitness.values
    fits = list(map(toolbox.evaluate, off))
    for ind, fit in zip(off, fits): ind.fitness.values = fit
    pop[:] = tools.selBest(pop + off, k=len(pop))
best = tools.selBest(pop, 1)[0]
print(sum(best))
```

### 5.3 Tareas combinatorias (TSP, knapsack)

* TSP: usar **operadores espec√≠ficos de permutaciones** (PMX, OX, CX, ER); el cruce cl√°sico no sirve directamente. &#x20;
* Knapsack 0-1: binario + fitness con restricciones / o MOEA. &#x20;

---

## 6) Buenas pr√°cticas (ingenier√≠a + docencia)

* **Semillas** y **presupuestos** (n evals) claros; registra configuraci√≥n y resultados.
* **Representaci√≥n acorde al problema** (p. ej., permutaciones para rutas).&#x20;
* **Elitismo/diversidad**: evita convergencia prematura (NSGA-II/III en MOEA).&#x20;
* Personaliza al dominio (NFL): ajusta operadores/encodings.&#x20;

---

## 7) Aplicaciones t√≠picas

* **Combinatoria**: TSP, knapsack, scheduling/job-shop.&#x20;
* **Machine Learning**: **LCS/XCS**, reglas, RL evolutivo.&#x20;
* **Neuroevoluci√≥n/GP**: evoluci√≥n de programas/√°rboles y grafos. &#x20;

---

## 8) Roadmap sugerido de notebooks

| Notebook                         | Tema                                               | Colab |
| -------------------------------- | -------------------------------------------------- | ----- |
| `01_intro_ea.ipynb`              | Motivaci√≥n, ciclo EA, NFL                          | ‚Äî     |
| `02_ga_sga.ipynb`                | SGA: ruleta, 1-punto, bit-flip, esquemas           | ‚Äî     |
| `03_es_de.ipynb`                 | ES ((Œº,Œª)/(Œº+Œª)) + DE (*rand/1*, *best/1*)         | ‚Äî     |
| `04_pso.ipynb`                   | PSO: ecuaciones y variantes                        | ‚Äî     |
| `05_moea_nsga.ipynb`             | Pareto, NSGA-II/III, hipervolumen                  | ‚Äî     |
| `06_combinatoria_tsp_knap.ipynb` | Operadores de permutaci√≥n (PMX/OX/CX/ER), knapsack | ‚Äî     |
| `07_gp.ipynb`                    | Programaci√≥n gen√©tica (√°rboles)                    | ‚Äî     |
| `08_lcs_xcs.ipynb`               | LCS/XCS + refuerzo                                 | ‚Äî     |

---

## 9) Ejercicios propuestos

### Teor√≠a

1. Demuestra por qu√© **elitismo + crowding** mejora preservaci√≥n de Pareto frente a NSGA cl√°sico.&#x20;
2. Compara **(Œº,Œª)** vs **(Œº+Œª)** respecto a exploraci√≥n/explotaci√≥n.&#x20;
3. Explica NFL y sus implicancias en el dise√±o de operadores.&#x20;

### Pr√°ctica

1. **SGA** sobre *OneMax* y **DE** sobre *Sphere*; reporta curva fitness-evaluaciones.&#x20;
2. **TSP** (50‚Äì100 ciudades): compara PMX/OX/CX/ER + 2-opt local.&#x20;
3. **Knapsack** multiobjetivo: usado con NSGA-II; visualiza el frente.&#x20;
4. **PSO vs GA** en 10 funciones de caja negra; analiza sensibilidad a $c_1,c_2$.&#x20;

---

## 10) Errores comunes

* Usar **crossover cl√°sico** en **permutaciones** (p. ej., TSP) ‚Üí genera inv√°lidos o destruye estructura; emplea PMX/OX/CX/ER.&#x20;
* Ignorar **diversidad** en MOEA ‚Üí colapso del frente; usa crowding/elitismo.&#x20;
* Representaci√≥n no acorde al problema (binario para reales finos o viceversa).&#x20;
* Asumir un **EA universalmente mejor** (violando NFL).&#x20;

---

## 11) Enlaces internos y bibliograf√≠a

* **Notebooks**: `./notebooks/`
* **Datos**: `./data/` (TSP, knapsack, configs)
* **Im√°genes**: `./images/`
* **Referencias**: `./references/`

**Bibliograf√≠a sugerida** (a√±ade en `references/bibliography.bib`):

* Eiben & Smith ‚Äî *Introduction to Evolutionary Computing* (Springer, 2007)
* Michalewicz ‚Äî *Genetic Algorithms + Data Structures = Evolution Programs* (3¬™ ed., 1996)
* Mitchell ‚Äî *Introduction to Genetic Algorithms* (MIT Press, 1996)
* Holland ‚Äî *Adaptation in Natural and Artificial Systems* (MIT Press, 1992)
* Goldberg ‚Äî *Genetic Algorithms in Search, Optimization and Machine Learning* (Addison-Wesley, 1989)&#x20;

---

## 12) Contribuci√≥n

1. Crea una rama: `feature/ea-tema`.
2. A√±ade datasets/configs en `data/` con `README.md` describiendo columnas/atributos.
3. Incluye notebooks autocontenidos (semillas fijas, dependencias indicadas).
4. Abre un **Pull Request** con resultados y figuras en `images/`.

---

## 13) Licencia

Este material se distribuye bajo **MIT** (c√≥digo) y sugiere **CC BY 4.0** para contenidos docentes (textos/figuras). Revisa `LICENSE` en la ra√≠z del repositorio.

---

## Ap√©ndice A ‚Äî Pseudoc√≥digo docente

**Esqueleto EA (gen√©rico)**&#x20;

```
EA(problem):
  P ‚Üê InicializarPoblaci√≥n()
  evaluar(P)
  while !criterio_parada:
      padres ‚Üê seleccionar_parental(P)
      hijos  ‚Üê recombinar_mutar(padres)
      evaluar(hijos)
      P ‚Üê seleccionar_ambiental(P, hijos)  # elitismo si aplica
  return mejor(P)
```

**SGA (binario)**&#x20;

```
SGA(f, n, l, pC, pM):
  P ‚Üê n individuos de l bits al azar
  while !parada:
      P' ‚Üê ‚àÖ
      repetir n/2 veces:
          x, y ‚Üê selecci√≥n_ruleta(P)
          if rand() < pC: x, y ‚Üê crossover_1p(x, y)
          x ‚Üê mut_bitflip(x, pM); y ‚Üê mut_bitflip(y, pM)
          P' ‚Üê P' ‚à™ {x, y}
      P ‚Üê P'  # reemplazo generacional
```

**DE (rand/1/bin)** &#x20;

```
DE(f, N, F, CR):
  P ‚Üê {x_i}^N inicial al azar
  while !parada:
      for cada i:
          a,b,c ‚Üê √≠ndices distintos de i
          v ‚Üê x_a + F*(x_b - x_c)
          u ‚Üê binomial_crossover(x_i, v, CR)  # al menos 1 gen de v
          x_i ‚Üê mejor(u, x_i)  # reemplazo si mejora
```

**PSO (gbest)**&#x20;

```
PSO(f, N, c1, c2):
  inicializar {x_i, v_i}; pBest_i ‚Üê x_i; gBest ‚Üê argmin f(pBest_i)
  while !parada:
      for i in 1..N:
          v_i ‚Üê v_i + c1*r()*(pBest_i - x_i) + c2*r()*(gBest - x_i)
          x_i ‚Üê x_i + v_i
          actualizar pBest_i y gBest
```

---

## Ap√©ndice B ‚Äî Plantilla m√≠nima de notebook

```markdown
# T√≠tulo: <Tema del notebook>

## Objetivos
- ‚Ä¶

## Problema / Dataset
- Ruta: data/‚Ä¶

## Configuraci√≥n
- Semilla: ‚Ä¶
- Presupuesto (evaluaciones / tiempo): ‚Ä¶

## Pasos
1. Definir representaci√≥n y operadores
2. Configurar selecci√≥n (parental/ambiental)
3. Ejecutar (k runs) y registrar m√©tricas
4. Analizar curvas y/o frente de Pareto

## Resultados
- M√©tricas / Figuras

## Conclusiones
- ‚Ä¶
```




